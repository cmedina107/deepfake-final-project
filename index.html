<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Deepfakes & Society: Technology, Ethics, and Impact</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      font-family: Arial, Helvetica, sans-serif;
      margin: 0;
      padding: 0;
      background: #0f172a;
      color: #e5e7eb;
    }
    header {
      background: #1e293b;
      padding: 30px 15px;
      text-align: center;
    }
    header h1 {
      margin: 0;
      font-size: 2rem;
    }
    header p {
      margin-top: 10px;
      color: #cbd5f5;
      max-width: 800px;
      margin-left: auto;
      margin-right: auto;
    }
    nav {
      background: #020617;
      padding: 10px 15px;
      position: sticky;
      top: 0;
      z-index: 10;
    }
    nav a {
      color: #e5e7eb;
      text-decoration: none;
      margin-right: 15px;
      font-size: 0.95rem;
    }
    nav a:hover {
      text-decoration: underline;
    }
    main {
      max-width: 900px;
      margin: 20px auto 40px auto;
      padding: 0 15px;
    }
    section {
      background: #020617;
      border-radius: 10px;
      padding: 20px;
      margin-bottom: 20px;
      box-shadow: 0 8px 20px rgba(0,0,0,0.35);
    }
    h2 {
      margin-top: 0;
      color: #bfdbfe;
    }
    h3 {
      color: #93c5fd;
    }
    p {
      line-height: 1.6;
      font-size: 0.98rem;
    }
    ul, ol {
      padding-left: 20px;
    }
    li {
      margin-bottom: 5px;
    }
    .tag {
      display: inline-block;
      background: #1d4ed8;
      color: white;
      padding: 3px 8px;
      border-radius: 999px;
      font-size: 0.75rem;
      margin-right: 5px;
      margin-bottom: 5px;
    }
    .two-column {
      display: grid;
      grid-template-columns: 1fr;
      gap: 16px;
    }
    @media (min-width: 768px) {
      .two-column {
        grid-template-columns: 1fr 1fr;
      }
    }
    .card {
      background: #020617;
      border-radius: 10px;
      padding: 15px 15px 10px 15px;
      border: 1px solid #1e293b;
    }
    .footer-note {
      font-size: 0.85rem;
      color: #9ca3af;
      margin-top: 10px;
    }
    a {
      color: #60a5fa;
    }
    .img-wrapper {
      text-align: center;
      margin: 22px 0;
    }
    .img-wrapper img {
      max-width: 100%;
      border-radius: 10px;
    }
    .img-caption {
      color: #9ca3af;
      font-size: 0.85rem;
      margin-top: 6px;
    }
  </style>
</head>
<body>
  <header>
    <h1>Deepfakes & Society: Technology, Ethics, and Impact</h1>
    <p>
      In this project, I look at deepfake technology, how it is being used in the real world, 
      and why it raises serious social and ethical questions for all of us, not just people in tech.
    </p>
  </header>

  <nav>
    <a href="#intro">Introduction</a>
    <a href="#applications">Applications</a>
    <a href="#ethics">Ethical Lenses</a>
    <a href="#discussion">Social Implications</a>
    <a href="#recommendations">Recommendations</a>
    <a href="#references">References</a>
  </nav>

  <main>
    <!-- INTRODUCTION -->
    <section id="intro">
      <h2>1. Introduction to Deepfake Technology</h2>
      <span class="tag">AI</span>
      <span class="tag">Generative Media</span>
      <span class="tag">Misinformation</span>

      <h3>What is a deepfake?</h3>
      <p>
        Deepfakes are realistic fake images, audio, or videos created using artificial intelligence. 
        Most deepfakes are made with machine learning models like generative adversarial networks (GANs) 
        or newer diffusion models. These models are trained on lots of real faces and voices, and then 
        they can generate new media that looks and sounds like a specific person.
      </p>

      <!-- Intro explainer video -->
      <div style="margin: 20px 0;">
        <iframe width="100%" height="315" 
          src="https://www.youtube.com/embed/Ro8b69VeL9U" 
          title="What are deepfakes? (Explainer video)" frameborder="0" 
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
          allowfullscreen>
        </iframe>
      </div>

      <p>
        For example, a deepfake video might show a politician giving a speech they never actually gave, 
        or a deepfake audio clip might sound like a family member asking you to send them money. 
        Because the quality can be so high, it is getting harder for regular people to tell what is real 
        and what is fake.
      </p>

      <h3>Why does this technology matter?</h3>
      <p>
        Deepfakes matter because they attack something we usually take for granted: that photos, videos, 
        and recordings show what really happened. This technology has some cool and creative uses, 
        but it also comes with serious risks, especially when it is used to lie, scam, or harass people.
      </p>
      <ul>
        <li><strong>Democracy:</strong> fake political content can confuse or mislead voters.</li>
        <li><strong>Cybersecurity and finance:</strong> scammers can impersonate bosses or coworkers.</li>
        <li><strong>Privacy and safety:</strong> people can be put into fake or sexual content without consent.</li>
        <li><strong>Trust in information:</strong> when everything can be faked, people may stop believing real evidence.</li>
      </ul>

      <p>
        Because of these issues, deepfakes are a good example of how advanced information technology 
        can create complex social problems that we have to think about carefully, not just from a 
        technical point of view, but also from an ethical one.
      </p>
    </section>

    <!-- APPLICATIONS -->
    <section id="applications">
      <h2>2. Real-World Applications and Use Cases</h2>
      <p>
        Below are real-world examples of deepfake technology being used in harmful ways. 
        Each case is based on news reports or research, not just hypotheticals.
      </p>

      <div class="card">
        <h3>Use Case 1: Deepfake Political Robocalls (Elections)</h3>

        <!-- Political deepfake video -->
        <div style="margin: 20px 0;">
          <iframe width="100%" height="315" 
            src="https://www.youtube.com/embed/wxEpPin8MWw" 
            title="How AI and deepfakes are changing politics – BBC News" frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
            allowfullscreen>
          </iframe>
        </div>

        <p>
          In January 2024, before the New Hampshire presidential primary, some voters received a robocall 
          that sounded like President Joe Biden. The call told them not to vote in the primary and to 
          “save” their vote for the general election instead. Investigators later found that the voice 
          was generated by an AI system that cloned Biden’s voice. New Hampshire officials and the 
          Federal Communications Commission (FCC) treated this as an attempt to interfere with the election 
          and later issued fines for the scheme.
        </p>

        <h4>Why this situation matters</h4>
        <ul>
          <li>It directly targeted voters with false information about when or how to vote.</li>
          <li>It used the fake voice of a real political figure to sound more believable.</li>
          <li>It shows how deepfakes can be used for voter suppression and election interference.</li>
        </ul>

        <p class="footer-note">
          This example shows that deepfakes are not just an online prank; they can be used as a serious tool 
          for political manipulation.
        </p>
      </div>

      <!-- Deepfake growth in election year -->
      <div class="img-wrapper">
        <img src="deepfakefraud.jpeg" alt="Deepfake growth in the 2024 election year infographic">
        <p class="img-caption">
          Deepfake use has surged during the 2024 election year in many countries, which increases the risk of
          election-related misinformation and manipulation.
        </p>
      </div>

      <!-- AI-powered fraud growth worldwide -->
      <div class="img-wrapper">
        <img src="electionfraud.png" alt="Explosive growth of AI-powered fraud around the world">
        <p class="img-caption">
          AI-powered identity fraud and deepfake-specific scams have grown rapidly across multiple regions,
          showing that financial and cyber risks are global, not isolated.
        </p>
      </div>

      <div class="card">
        <h3>Use Case 2: $25 Million Deepfake CEO Scam (Financial Fraud)</h3>

        <p>
          In early 2024, the Hong Kong office of a global engineering and consulting firm lost about 
          $25 million to a deepfake scam. An employee joined what looked like a normal video conference 
          with the company’s chief financial officer (CFO) and several other executives. In reality, 
          every “person” on the call except the employee was a deepfake created with AI-generated video 
          and audio. Believing the request was legitimate, the employee followed the fake CFO’s instructions 
          and transferred money to accounts controlled by criminals.
        </p>

        <!-- Scam deepfake video -->
        <div style="margin: 20px 0;">
          <iframe width="100%" height="315" 
            src="https://www.youtube.com/embed/JwC6DRQnIt0" 
            title="CFO digitally cloned, $25 million stolen using deepfakes" frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
            allowfullscreen>
          </iframe>
        </div>

        <h4>Why this situation matters</h4>
        <ul>
          <li>Typical security habits like checking the email sender were not enough.</li>
          <li>The scam combined social engineering with realistic deepfake visuals and audio.</li>
          <li>It shows that people may trust video calls too much, assuming “if I see them, it must be real.”</li>
        </ul>

        <p class="footer-note">
          This case shows that deepfakes open up a new kind of attack surface in organizations: 
          fake people in meetings, not just fake emails.
        </p>
      </div>

      <div class="card">
        <h3>Use Case 3: Non-Consensual Deepfake Abuse (Privacy & Harassment)</h3>
        <p>
          Deepfake tools are also being used to create non-consensual sexual or abusive content. 
          Studies and news investigations have found that a large amount of deepfake content online 
          targets women, including private individuals, students, journalists, and politicians. 
          Sometimes students use “nudifying” apps or deepfake tools to create fake sexual images of classmates 
          and share them in group chats, which can cause serious emotional and social harm for the victims.
        </p>

        <h4>Why this situation matters</h4>
        <ul>
          <li>It violates privacy and consent, even if the video is technically “fake.”</li>
          <li>Victims can face embarrassment, bullying, and long-term mental health issues.</li>
          <li>Laws in many places are still catching up and may not clearly cover this type of abuse.</li>
        </ul>

        <p class="footer-note">
          This use case shows that deepfakes often make existing problems like harassment and sexism worse, 
          especially for women and girls.
        </p>
      </div>
    </section>

    <!-- ETHICAL LENSES -->
    <section id="ethics">
      <h2>3. Ethical Analysis Using Two Lenses</h2>
      <p>
        To think more carefully about deepfakes, it helps to look at them through different ethical lenses. 
        Here, I focus on <strong>utilitarianism</strong> and <strong>deontology</strong>, which are two common 
        approaches in ethics.
      </p>

      <div class="two-column">
        <div class="card">
          <h3>Lens 1: Utilitarianism</h3>
          <p>
            Utilitarianism is an outcome-based approach. An action is considered ethical if it produces 
            “the greatest good for the greatest number” and reduces overall harm.
          </p>

          <h4>Potential benefits of deepfakes</h4>
          <ul>
            <li>Movies and games can create realistic scenes without putting actors at risk.</li>
            <li>Education can use digital versions of historical figures to make lessons more engaging.</li>
            <li>Accessibility tools can generate translations or dubbing in a familiar voice.</li>
          </ul>

          <h4>Harms in the real-world cases</h4>
          <ul>
            <li>Political robocalls mislead voters and damage trust in elections.</li>
            <li>Deepfake scams cause huge financial losses and stress for employees.</li>
            <li>Non-consensual deepfake abuse harms victims’ mental health and reputations.</li>
          </ul>

          <p>
            From a utilitarian point of view, the current balance of deepfake uses seems negative. 
            Right now, the large-scale harms to trust, democracy, and individual well-being outweigh 
            the entertainment and convenience benefits. Under this lens, deepfakes are not ethically 
            acceptable unless strong protections are added to reduce the harms.
          </p>
        </div>

        <div class="card">
          <h3>Lens 2: Deontology (Duty & Rights)</h3>
          <p>
            Deontological ethics focuses on duties, rules, and rights instead of just outcomes. 
            An action can be wrong even if it has good results, if it breaks an important moral rule.
          </p>

          <h4>Key duties and rights involved</h4>
          <ul>
            <li>The duty to tell the truth and avoid deception.</li>
            <li>The right to control how your own image and voice are used.</li>
            <li>The duty to respect other people’s autonomy and consent.</li>
          </ul>

          <h4>Deepfakes under deontology</h4>
          <ul>
            <li>Political deepfake robocalls violate honesty and respect for voters.</li>
            <li>Deepfake CEO scams break trust and use people as tools to move money.</li>
            <li>Non-consensual deepfake images ignore victims’ rights to privacy and consent.</li>
          </ul>

          <p>
            From a deontological perspective, many current uses of deepfakes are “wrong in themselves,” 
            even if someone argues they have side benefits (like going viral or making money). 
            They rely on deception and disrespect people’s basic rights.
          </p>
        </div>
      </div>
    </section>

    <!-- SOCIAL IMPLICATIONS -->
    <section id="discussion">
      <h2>4. Social and Political Implications</h2>
      <p>
        Deepfake technology doesn’t exist in a vacuum. It fits into a bigger system that includes 
        social media, politics, law, and everyday relationships. Some key implications include:
      </p>

      <ul>
        <li>
          <strong>Erosion of trust in evidence:</strong> If any video or audio clip might be fake, 
          people may stop trusting real recordings. This hurts journalism, court cases, and even 
          how we remember important events.
        </li>
        <li>
          <strong>Democracy and elections:</strong> Deepfakes can be used to push fake speeches, 
          fake endorsements, and fake scandals, especially right before an election when there isn’t 
          much time to fact-check.
        </li>
        <li>
          <strong>Cybercrime and scams:</strong> Attackers can pretend to be bosses, coworkers, or 
          family members to get people to send money or share private information.
        </li>
        <li>
          <strong>Unequal impact:</strong> Women and minorities are more often targeted by deepfake abuse, 
          which can reinforce existing inequalities and discrimination.
        </li>
        <li>
          <strong>Legal gaps:</strong> Many legal systems were created before deepfakes existed, 
          so it is not always clear how to punish or prevent this kind of harm.
        </li>
      </ul>
    </section>

    <!-- RECOMMENDATIONS -->
    <section id="recommendations">
      <h2>5. Recommendations for Less Harmful Use</h2>
      <p>
        Deepfakes are probably not going away, so the question becomes how to reduce the harm. 
        A mix of technical, educational, and policy solutions is likely needed.
      </p>

      <h3>Technical Strategies</h3>
      <ul>
        <li>Require platforms to label or watermark AI-generated media when they can detect it.</li>
        <li>Invest in deepfake detection tools and share them with journalists, election officials, and banks.</li>
        <li>Use strong identity verification for high-risk actions, such as large money transfers or executive approvals.</li>
      </ul>

      <h3>Educational Strategies</h3>
      <ul>
        <li>Add media literacy to school curricula so students learn to question suspicious videos and audio.</li>
        <li>Train employees about AI-based scams and encourage them to double-check unusual requests.</li>
        <li>Raise public awareness that “seeing something” online does not automatically mean it is real.</li>
      </ul>

      <h3>Policy and Legal Strategies</h3>
      <ul>
        <li>Update laws to clearly criminalize non-consensual deepfake pornography and identity abuse.</li>
        <li>Regulate political deepfakes by requiring clear labels or limiting deceptive uses in campaigns.</li>
        <li>Encourage international cooperation, since deepfake content can spread across countries instantly.</li>
      </ul>

      <p>
        Overall, deepfake technology has both creative potential and serious dangers. 
        Right now, many of the most visible uses are harmful. With better rules, better tools, 
        and more awareness, it may be possible to keep some of the benefits while reducing the worst risks.
      </p>
    </section>

    <!-- REFERENCES -->
    <section id="references">
      <h2>6. References (Real-World Sources)</h2>
      <p>
        These sources discuss the examples and issues covered on this site:
      </p>
      <ul>
        <li>
          Associated Press. (2024, January 22). <em>Fake Biden robocall being investigated in New Hampshire.</em>
        </li>
        <li>
          Federal Communications Commission. (2024, September 26). <em>FCC fines man behind election interference scheme 
          $6 million for sending illegal robocalls that used deepfake generative AI technology.</em>
        </li>
        <li>
          Trend Micro. (2024, February 7). <em>Deepfake CFO video calls result in $25MM in damages.</em>
        </li>
        <li>
          World Economic Forum. (2025, February 4). <em>Cybercrime: Lessons learned from a $25m deepfake attack.</em>
        </li>
        <li>
          Lundberg, E. (2024). The potential effects of deepfakes on news media and democracy. <em>AI & Society.</em>
        </li>
        <li>
          Ma’arif, A. (2025). Social, legal, and ethical implications of AI-generated deepfake pornography. 
          <em>Journal of Responsible Technology.</em>
        </li>
        <li>
          Sumsub / Statista. (2023–2024). <em>Deepfake and AI-powered fraud infographics.</em>
        </li>
      </ul>

      <p class="footer-note">
        This site is for educational purposes for a college course on IT and ethics. 
        It summarizes public reporting and research on deepfake technology and its social impacts.
      </p>
    </section>
  </main>
</body>
</html>
